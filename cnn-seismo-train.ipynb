{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10649529,"sourceType":"datasetVersion","datasetId":6594187},{"sourceId":11665917,"sourceType":"datasetVersion","datasetId":7321515}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nCROP_LEFT = 94\nCROP_TOP = 41\nCROP_RIGHT = 13","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Обрезка изображений и аугментация данных","metadata":{}},{"cell_type":"code","source":"# Указать пути до папок\ninput_dataset_path = \"/kaggle/input/cropp-split-seismo-dataset-task-a\"\ncropped_dataset_path = \"/kaggle/working/cropped-dataset\"\naugmented_dataset_path = \"/kaggle/working/augmented-dataset\"\n\n# Кусок по обрезке изображений\ndataset_splits = [\"train\", \"test\", \"val\"]\nfor split in dataset_splits:\n    split_input_path = os.path.join(input_dataset_path, split)\n    split_cropped_path = os.path.join(cropped_dataset_path, split)\n    os.makedirs(split_cropped_path, exist_ok=True)\n    \n    for class_name in os.listdir(split_input_path):\n        class_input_path = os.path.join(split_input_path, class_name)\n        class_cropped_path = os.path.join(split_cropped_path, class_name)\n        os.makedirs(class_cropped_path, exist_ok=True)\n        \n        if os.path.isdir(class_input_path):\n            for image_name in os.listdir(class_input_path):\n                img_path = os.path.join(class_input_path, image_name)\n                img = cv2.imread(img_path)\n                if img is None:\n                    continue\n                h, w, _ = img.shape\n                # Обрезаем по вышеуказанным константам 3/4 краёв изображений\n                cropped_img = img[CROP_TOP:, CROP_LEFT:w - CROP_RIGHT]\n                output_path = os.path.join(class_cropped_path, image_name)\n                cv2.imwrite(output_path, cropped_img)\n\nprint(\"Обрезка изображений завершена. Сохранено в:\", cropped_dataset_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:23:51.394962Z","iopub.execute_input":"2025-04-29T19:23:51.395182Z","iopub.status.idle":"2025-04-29T19:24:41.571100Z","shell.execute_reply.started":"2025-04-29T19:23:51.395161Z","shell.execute_reply":"2025-04-29T19:24:41.570387Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Аугментация (расширение) датасета","metadata":{}},{"cell_type":"code","source":"for split in dataset_splits:\n    split_cropped_path = os.path.join(cropped_dataset_path, split)\n    split_aug_path = os.path.join(augmented_dataset_path, split)\n    os.makedirs(split_aug_path, exist_ok=True)\n    \n    for class_name in os.listdir(split_cropped_path):\n        class_cropped_path = os.path.join(split_cropped_path, class_name)\n        class_aug_path = os.path.join(split_aug_path, class_name)\n        os.makedirs(class_aug_path, exist_ok=True)\n        \n        if os.path.isdir(class_cropped_path):\n            for image_name in os.listdir(class_cropped_path):\n                base_name, ext = os.path.splitext(image_name)\n                img_path = os.path.join(class_cropped_path, image_name)\n                img = cv2.imread(img_path)\n                if img is None:\n                    continue\n                \n                # Сохраняем оригинал\n                output_original = os.path.join(class_aug_path, base_name + ext)\n                cv2.imwrite(output_original, img)\n                \n                # Аугментация 1 - горизонтальное отзеркаливание\n                mirrored = cv2.flip(img, 1)\n                output_mirrored = os.path.join(class_aug_path, base_name + \"_mirrored\" + ext)\n                cv2.imwrite(output_mirrored, mirrored)\n                \n                # определяем разрешение изображения\n                h, w, _ = img.shape\n                mid = w // 2\n                \n                # Аугментация 2 - правая сторона отзеркаливается на левую (две правых стороны)\n                right_half = img[:, mid:]\n                left_mirror = cv2.flip(right_half, 1)\n                double_r = np.concatenate((left_mirror, right_half), axis=1)\n                output_double_r = os.path.join(class_aug_path, base_name + \"_double_r\" + ext)\n                cv2.imwrite(output_double_r, double_r)\n                \n                # Аугментация 3 - левая сторона отзеркаливается на правую (две левых стороны)\n                left_half = img[:, :mid]\n                right_mirror = cv2.flip(left_half, 1)\n                double_l = np.concatenate((left_half, right_mirror), axis=1)\n                output_double_l = os.path.join(class_aug_path, base_name + \"_double_l\" + ext)\n                cv2.imwrite(output_double_l, double_l)\n\nprint(\"Аугментация завершена. Сохранено в: \", augmented_dataset_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:24:41.571908Z","iopub.execute_input":"2025-04-29T19:24:41.572317Z","iopub.status.idle":"2025-04-29T19:26:32.973130Z","shell.execute_reply.started":"2025-04-29T19:24:41.572282Z","shell.execute_reply":"2025-04-29T19:26:32.972396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Показ аугментации","metadata":{}},{"cell_type":"code","source":"def display_augmented_images(subfolder_root, image_base_name, ext=\".png\"):\n    file_names = [\n        image_base_name + ext,\n        image_base_name + \"_mirrored\" + ext,\n        image_base_name + \"_double_r\" + ext,\n        image_base_name + \"_double_l\" + ext\n    ]\n    images = []\n    for file in file_names:\n        img_path = os.path.join(subfolder_root, file)\n        img = cv2.imread(img_path)\n        if img is not None:\n            # Переводит BRG -> RGB для визуализации\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            images.append(img)\n        else:\n            print(\"Image not found:\", img_path)\n    \n    # Отображение в матплотлибе\n    plt.figure(figsize=(16, 4))\n    titles = [\"Оригинал\", \"Отзеркаленное\", \"Две правые половины\", \"Две левые половины\"]\n    for i, image in enumerate(images):\n        plt.subplot(1, 4, i + 1)\n        plt.imshow(image)\n        plt.title(titles[i])\n        plt.axis(\"off\")\n    plt.show()\nsubfolder_root = \"/kaggle/working/augmented-dataset/val/brak_Station\"\nimage_base_name = \"_000110\"  # изображение для примеры\ndisplay_augmented_images(subfolder_root, image_base_name, ext=\".png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:26:32.973931Z","iopub.execute_input":"2025-04-29T19:26:32.974246Z","iopub.status.idle":"2025-04-29T19:26:34.773088Z","shell.execute_reply.started":"2025-04-29T19:26:32.974223Z","shell.execute_reply":"2025-04-29T19:26:34.772155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Удаляем плохие аугментации","metadata":{}},{"cell_type":"code","source":"os.remove(\"/kaggle/working/augmented-dataset/test/brak_Station/_000108_double_l.png\")\nos.remove(\"/kaggle/working/augmented-dataset/test/brak_Station/_000174_double_r.png\")\nos.remove(\"/kaggle/working/augmented-dataset/train/brak_Station/_000030_double_r.png\")\nos.remove(\"/kaggle/working/augmented-dataset/train/brak_Station/_000037_double_r.png\")\nos.remove(\"/kaggle/working/augmented-dataset/train/brak_Station/_000043_mirrored.png\")\nos.remove(\"/kaggle/working/augmented-dataset/train/brak_Station/_000175_double_r.png\")\nos.remove(\"/kaggle/working/augmented-dataset/train/brak_Station/_000257_double_l.png\")\n# os.remove(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:26:34.774597Z","iopub.execute_input":"2025-04-29T19:26:34.774870Z","iopub.status.idle":"2025-04-29T19:26:34.789090Z","shell.execute_reply.started":"2025-04-29T19:26:34.774837Z","shell.execute_reply":"2025-04-29T19:26:34.788260Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ручной перенос изображений между выборками для лучшего баланса ","metadata":{}},{"cell_type":"code","source":"import shutil\n\nsource_folder = \"/kaggle/working/augmented-dataset/train/brak_Station/\" #откуда\ndestination_folder = \"/kaggle/working/augmented-dataset/val/brak_Station/\" #куда\n\n# Указываем изображения для перемещения\nfiles_to_move = [\"_000257_double_l.png\", \"_000189.png\"]\n\n# Создаём конечную папку\nos.makedirs(destination_folder, exist_ok=True)\n\n# Перенос\nfor file_name in files_to_move:\n    source_path = os.path.join(source_folder, file_name)\n    destination_path = os.path.join(destination_folder, file_name)\n    \n    if os.path.exists(source_path):\n        shutil.move(source_path, destination_path)\n        print(f\"Перемещено: {file_name}\")\n    else:\n        print(f\"Файл не найден: {file_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:26:34.790192Z","iopub.execute_input":"2025-04-29T19:26:34.790494Z","iopub.status.idle":"2025-04-29T19:26:35.421366Z","shell.execute_reply.started":"2025-04-29T19:26:34.790473Z","shell.execute_reply":"2025-04-29T19:26:35.420341Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Распределение изображений по подвыборкам","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nbase_dir = \"/kaggle/working/augmented-dataset\"\nsplits   = [\"train\", \"val\", \"test\"]\n\nrecords = []\nfor split in splits:\n    split_dir = os.path.join(base_dir, split)\n    if not os.path.isdir(split_dir):\n        print(f\"Сплит не найден: {split_dir}\")\n        continue\n\n    for class_name in os.listdir(split_dir):\n        class_dir = os.path.join(split_dir, class_name)\n        if not os.path.isdir(class_dir):\n            continue\n\n        # Count PNG files (case‐insensitive)\n        png_files = [f for f in os.listdir(class_dir)\n                     if f.lower().endswith(\".png\")]\n\n        records.append({\n            \"подвыборка\":       split,\n            \"класс\":       class_name,\n            \"число изображений\":   len(png_files)\n        })\n\ndf = pd.DataFrame(records)\n\nfor split, group in df.groupby(\"подвыборка\"):\n    print(f\"== {split.upper():10s} ==\")\n    for _, row in group.iterrows():\n        print(f\"{row['класс']:<20s} : {row['число изображений']}\")\n\ndisplay(df.sort_values([\"подвыборка\",\"класс\"]).reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:26:35.422388Z","iopub.execute_input":"2025-04-29T19:26:35.422711Z","iopub.status.idle":"2025-04-29T19:26:35.470123Z","shell.execute_reply.started":"2025-04-29T19:26:35.422665Z","shell.execute_reply":"2025-04-29T19:26:35.469329Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Инициализация и обучение 1й модели в каскаде","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Subset\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n\n# Гиперпараметры для модели 1 (можно менять)\nnum_epochs_model1 = 10 # число эпох\nbatch_size_model1 = 16 # размер батча \nlearning_rate_model1 = 1e-3 # шаг обучения\n\ndata_dir = \"/kaggle/working/augmented-dataset\"\ntrain_dir = os.path.join(data_dir, \"train\")\nval_dir   = os.path.join(data_dir, \"val\")\ntest_dir  = os.path.join(data_dir, \"test\")\n\n# Подгон формата изображений под ResNet сеть\ndata_transforms = {\n    \"train\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ]),\n    \"val\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ]),\n    \"test\": transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n}\n\ntrain_dataset_orig = datasets.ImageFolder(root=train_dir, transform=data_transforms[\"train\"])\nval_dataset_orig   = datasets.ImageFolder(root=val_dir, transform=data_transforms[\"val\"])\ntest_dataset_orig  = datasets.ImageFolder(root=test_dir, transform=data_transforms[\"test\"])\n\nprint(\"Оригинальные классы:\", train_dataset_orig.classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:33:41.048188Z","iopub.execute_input":"2025-04-29T19:33:41.048551Z","iopub.status.idle":"2025-04-29T19:33:41.060789Z","shell.execute_reply.started":"2025-04-29T19:33:41.048524Z","shell.execute_reply":"2025-04-29T19:33:41.059908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MappedDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Меняет отображения классов для выбранной модели\n    \"\"\"\n    def __init__(self, dataset, mapping):\n        self.dataset = dataset\n        self.mapping = mapping\n    def __getitem__(self, index):\n        img, label = self.dataset[index]\n        return img, self.mapping[label]\n    def __len__(self):\n        return len(self.dataset)\n\ndef filter_by_classes(dataset, target_class_names):\n    indices = []\n    for i in range(len(dataset)):\n        _, label = dataset[i]\n        if dataset.classes[label] in target_class_names:\n            indices.append(i)\n    return Subset(dataset, indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:33:41.061742Z","iopub.execute_input":"2025-04-29T19:33:41.062086Z","iopub.status.idle":"2025-04-29T19:33:41.075977Z","shell.execute_reply.started":"2025-04-29T19:33:41.062065Z","shell.execute_reply":"2025-04-29T19:33:41.075122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Словарь для отображения оригинальных меток классов в сокращённый набор классов для модели №1\nmapping1 = {}\nfor i, cls in enumerate(train_dataset_orig.classes):\n    if cls in [\"noise_DNS\", \"noise_Tip-off\"]:\n        mapping1[i] = 2  # Объединение двух шумовых классов в один — \"объединённый шум\"\n    elif cls == \"brak_Empty zone\":\n        mapping1[i] = 0  # Класс брака: \"пустая зона\"\n    elif cls == \"brak_Station\":\n        mapping1[i] = 1  # Класс брака: \"станция\"\n\n# Названия классов, соответствующие новой модели №1\nmodel1_classes = [\"brak_Empty zone\", \"brak_Station\", \"noise_combined\"]\nprint(\"Классы, используемые в модели №1:\", model1_classes)\n\n# Обёртка для исходных датасетов, чтобы применить отображение меток (mapping1)\ntrain_dataset_model1 = MappedDataset(train_dataset_orig, mapping1)\nval_dataset_model1   = MappedDataset(val_dataset_orig, mapping1)\ntest_dataset_model1  = MappedDataset(test_dataset_orig, mapping1)\n\n# Загрузчики данных (DataLoader) для модели №1\n# Здесь используется отображённый датасет, размер батча задаётся переменной batch_size_model1\ntrain_loader_model1 = DataLoader(train_dataset_model1, batch_size=batch_size_model1, shuffle=True, num_workers=2)\nval_loader_model1   = DataLoader(val_dataset_model1, batch_size=batch_size_model1, shuffle=False, num_workers=2)\ntest_loader_model1  = DataLoader(test_dataset_model1, batch_size=batch_size_model1, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:33:41.077184Z","iopub.execute_input":"2025-04-29T19:33:41.077453Z","iopub.status.idle":"2025-04-29T19:33:41.096856Z","shell.execute_reply.started":"2025-04-29T19:33:41.077434Z","shell.execute_reply":"2025-04-29T19:33:41.095906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel1 = models.resnet18(pretrained=True) # инициализация resnet18 (CNN)\nnum_ftrs = model1.fc.in_features \nmodel1.fc = nn.Linear(num_ftrs, len(model1_classes)) # переопределение выходных слоёв для дообучения\nmodel1 = model1.to(device) # перенос модели на GPU\n\ncriterion1 = nn.CrossEntropyLoss() #функция потерь\noptimizer1 = optim.Adam(model1.parameters(), lr=learning_rate_model1) # оптимизатор","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:33:41.097954Z","iopub.execute_input":"2025-04-29T19:33:41.098217Z","iopub.status.idle":"2025-04-29T19:33:42.584679Z","shell.execute_reply.started":"2025-04-29T19:33:41.098190Z","shell.execute_reply":"2025-04-29T19:33:42.583973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Обучение модели №1 с сохранением лучшей версии ---\nbest_val_acc1 = 0.0  # Лучшая достигнутая точность на валидации\ntrain_losses_model1, val_losses_model1 = [], []  # Списки для хранения значений лосса на тренировке и валидации\ntrain_accs_model1, val_accs_model1 = [], []      # Списки для хранения точности на тренировке и валидации\n\nprint(\"\\nНачало обучения модели №1...\")\nfor epoch in range(num_epochs_model1):\n    # --- Фаза обучения ---\n    model1.train()  # Установка модели в режим обучения\n    running_loss, running_corrects = 0.0, 0  # Суммарный лосс и число правильных предсказаний\n\n    for inputs, labels in tqdm(train_loader_model1, desc=f\"Модель №1 Эпоха {epoch+1}/{num_epochs_model1} [Обучение]\"):\n        inputs, labels = inputs.to(device), labels.to(device)  # Перенос данных на устройство (CPU или GPU)\n        optimizer1.zero_grad()  # Обнуление градиентов\n        outputs = model1(inputs)  # Прямой проход модели\n        loss = criterion1(outputs, labels)  # Вычисление значения функции потерь\n        loss.backward()  # Обратное распространение ошибки\n        optimizer1.step()  # Шаг оптимизации\n\n        running_loss += loss.item() * inputs.size(0)  # Накопление значения функции потерь\n        preds = outputs.argmax(dim=1)  # Предсказанные метки (по максимальному значению)\n        running_corrects += (preds == labels).sum().item()  # Подсчёт правильных предсказаний\n\n    epoch_loss = running_loss / len(train_dataset_model1)  # Средний лосс на эпохе\n    epoch_acc  = running_corrects / len(train_dataset_model1)  # Средняя точность на эпохе\n    train_losses_model1.append(epoch_loss)\n    train_accs_model1.append(epoch_acc)\n\n    # --- Фаза валидации ---\n    model1.eval()  # Перевод модели в режим оценки\n    val_running_loss, val_running_corrects = 0.0, 0\n    with torch.no_grad():  # Отключение градиентов\n        for inputs, labels in tqdm(val_loader_model1, desc=f\"Модель №1 Эпоха {epoch+1}/{num_epochs_model1} [Валидация]\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model1(inputs)\n            loss = criterion1(outputs, labels)\n            val_running_loss += loss.item() * inputs.size(0)\n            preds = outputs.argmax(dim=1)\n            val_running_corrects += (preds == labels).sum().item()\n\n    epoch_val_loss = val_running_loss / len(val_dataset_model1)  # Средний валидационный лосс\n    epoch_val_acc  = val_running_corrects / len(val_dataset_model1)  # Средняя точность на валидации\n    val_losses_model1.append(epoch_val_loss)\n    val_accs_model1.append(epoch_val_acc)\n\n    print(f\"Эпоха {epoch+1}/{num_epochs_model1} — \"\n          f\"Обучение: лосс = {epoch_loss:.4f}, точность = {epoch_acc:.4f} | \"\n          f\"Валидация: лосс = {epoch_val_loss:.4f}, точность = {epoch_val_acc:.4f}\")\n\n    # --- Сохранение лучшей модели ---\n    if epoch_val_acc > best_val_acc1:\n        best_val_acc1 = epoch_val_acc\n        torch.save(model1.state_dict(), '/kaggle/working/model1_best.pth')\n        print(f\"  → Новая лучшая модель! Сохранено как model1_best.pth (валидационная точность: {best_val_acc1:.4f})\")\n\n# Визуализация лоссов обучения и валидации для модели №1\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs_model1 + 1), train_losses_model1, label=\"Лосс на обучении\")\nplt.plot(range(1, num_epochs_model1 + 1), val_losses_model1, label=\"Лосс на валидации\")\nplt.xlabel(\"Эпоха\")\nplt.ylabel(\"Значение функции потерь\")\nplt.title(\"Модель №1: динамика функции потерь на обучении и валидации\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:33:42.585499Z","iopub.execute_input":"2025-04-29T19:33:42.585725Z","iopub.status.idle":"2025-04-29T19:37:55.720139Z","shell.execute_reply.started":"2025-04-29T19:33:42.585706Z","shell.execute_reply":"2025-04-29T19:37:55.719124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Построение матрицы ошибок для модели №1 ---\nmodel1.eval()  # Перевод модели в режим оценки\nall_preds = []   # Предсказанные метки\nall_labels = []  # Истинные метки\n\nwith torch.no_grad():  # Отключаем градиенты\n    for inputs, labels in tqdm(val_loader_model1, desc=\"Модель №1: Матрица ошибок\"):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model1(inputs)\n        _, preds = torch.max(outputs, 1)  # Получаем индексы классов с максимальной вероятностью\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Вычисление матрицы ошибок\ncm1 = confusion_matrix(all_labels, all_preds)\n\n# Визуализация матрицы ошибок с подписями классов\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm1, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=model1_classes,\n            yticklabels=model1_classes)\nplt.xlabel(\"Предсказанный класс\")\nplt.ylabel(\"Истинный класс\")\nplt.title(\"Модель №1: Матрица ошибок на валидации\")\nplt.show()\n\n\n# Функция отображения изображения, приведённого к исходному виду (unnormalize)\ndef imshow(inp):\n    \"\"\"Отображает изображение из тензора (обратная нормализация).\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    inp = (inp * std) + mean  # Обратная нормализация\n    inp = np.clip(inp, 0, 1)  # Ограничение значений до диапазона [0, 1]\n    plt.imshow(inp)\n    plt.axis(\"off\")\n\n\n##############################\n# Инференс (предсказание) для модели №1\n##############################\nmodel1.eval()  # Режим оценки модели\n\nall_images_1 = []  # Список изображений\nall_labels_1 = []  # Истинные метки\nall_preds_1 = []   # Предсказанные метки\n\nwith torch.no_grad():\n    for inputs, labels in val_loader_model1:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model1(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        # Сохраняем изображения и метки\n        for i in range(inputs.size(0)):\n            all_images_1.append(inputs[i].cpu())\n            all_labels_1.append(labels[i].item())\n            all_preds_1.append(preds[i].item())\n\n# Визуализация предсказаний\nnum_images_1 = len(all_images_1)\ncols = 4  # Количество изображений в строке\nrows = math.ceil(num_images_1 / cols)\n\nplt.figure(figsize=(cols * 4, rows * 4))\nfor idx in range(num_images_1):\n    ax = plt.subplot(rows, cols, idx + 1)\n    imshow(all_images_1[idx])\n    true_label = model1_classes[all_labels_1[idx]]\n    pred_label = model1_classes[all_preds_1[idx]]\n    ax.set_title(f\"Истина: {true_label}\\nПредсказание: {pred_label}\", fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:37:55.722205Z","iopub.execute_input":"2025-04-29T19:37:55.722497Z","iopub.status.idle":"2025-04-29T19:38:18.096150Z","shell.execute_reply.started":"2025-04-29T19:37:55.722472Z","shell.execute_reply":"2025-04-29T19:38:18.095153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Инициализация и обучение 2й модели в каскаде","metadata":{}},{"cell_type":"code","source":"# Гиперпараметры для модели №2\nnum_epochs_model2 = 10  # Количество эпох обучения\nbatch_size_model2 = 16  # Размер батча\nlearning_rate_model2 = 1e-4  # Скорость обучения\n\n# Целевые классы для модели №2 — только шумы\nmodel2_target_names = [\"noise_DNS\", \"noise_Tip-off\"]\nprint(\"Классы модели №2:\", model2_target_names)\n\n# Фильтрация исходных датасетов: оставляем только шумовые классы\ntrain_subset_model2 = filter_by_classes(train_dataset_orig, model2_target_names)\nval_subset_model2   = filter_by_classes(val_dataset_orig, model2_target_names)\ntest_subset_model2  = filter_by_classes(test_dataset_orig, model2_target_names)\n\n# Создание отображения: преобразуем оригинальные индексы классов к новым (0 и 1)\n# Например: {\"noise_DNS\": 0, \"noise_Tip-off\": 1}\nmapping2 = {}\nfor i, cls in enumerate(train_dataset_orig.classes):\n    if cls == \"noise_DNS\":\n        mapping2[i] = 0\n    elif cls == \"noise_Tip-off\":\n        mapping2[i] = 1\n\n# Оборачивание отфильтрованных датасетов с новой схемой отображения меток\ntrain_dataset_model2 = MappedDataset(train_subset_model2, mapping2)\nval_dataset_model2   = MappedDataset(val_subset_model2, mapping2)\ntest_dataset_model2  = MappedDataset(test_subset_model2, mapping2)\n\n# Загрузчики данных для модели №2\ntrain_loader_model2 = DataLoader(train_dataset_model2, batch_size=batch_size_model2, shuffle=True, num_workers=2)\nval_loader_model2   = DataLoader(val_dataset_model2, batch_size=batch_size_model2, shuffle=False, num_workers=2)\ntest_loader_model2  = DataLoader(test_dataset_model2, batch_size=batch_size_model2, shuffle=False, num_workers=2)\n\n# Создание модели №2 на базе ResNet18 (предобученная версия)\nmodel2 = models.resnet18(pretrained=True)\nnum_ftrs2 = model2.fc.in_features  # Размер входа в финальный полносвязный слой\nmodel2.fc = nn.Linear(num_ftrs2, len(model2_target_names))  # Замена выходного слоя на 2-классовый\nmodel2 = model2.to(device)  # Перенос модели на выбранное устройство\n\n# Функция потерь и оптимизатор для модели №2\ncriterion2 = nn.CrossEntropyLoss()  # Кросс-энтропия для многоклассовой классификации\noptimizer2 = optim.Adam(model2.parameters(), lr=learning_rate_model2)  # Адам-оптимизатор","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:38:18.097430Z","iopub.execute_input":"2025-04-29T19:38:18.097713Z","iopub.status.idle":"2025-04-29T19:39:07.038912Z","shell.execute_reply.started":"2025-04-29T19:38:18.097689Z","shell.execute_reply":"2025-04-29T19:39:07.038237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Обучение модели №2 с сохранением лучшей версии ---\nbest_val_acc2 = 0.0  # Лучшая достигнутая точность на валидации\ntrain_losses_model2, val_losses_model2 = [], []  # Списки лоссов на обучении и валидации\ntrain_accs_model2, val_accs_model2 = [], []      # Списки точности на обучении и валидации\n\nprint(\"\\nНачало обучения модели №2...\")\nfor epoch in range(num_epochs_model2):\n    # --- Фаза обучения ---\n    model2.train()  # Установка режима обучения\n    running_loss, running_corrects = 0.0, 0  # Суммарный лосс и количество правильных предсказаний\n\n    for inputs, labels in tqdm(train_loader_model2, desc=f\"Модель №2 Эпоха {epoch+1}/{num_epochs_model2} [Обучение]\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer2.zero_grad()  # Обнуление градиентов\n        outputs = model2(inputs)  # Прямой проход\n        loss = criterion2(outputs, labels)  # Вычисление функции потерь\n        loss.backward()  # Обратное распространение ошибки\n        optimizer2.step()  # Шаг оптимизации\n\n        running_loss += loss.item() * inputs.size(0)  # Умножение лосса на размер батча\n        preds = outputs.argmax(dim=1)  # Получение предсказаний\n        running_corrects += (preds == labels).sum().item()  # Подсчёт верных предсказаний\n\n    # Средние значения лосса и точности на обучении\n    epoch_loss = running_loss / len(train_dataset_model2)\n    epoch_acc  = running_corrects / len(train_dataset_model2)\n    train_losses_model2.append(epoch_loss)\n    train_accs_model2.append(epoch_acc)\n\n    # --- Фаза валидации ---\n    model2.eval()  # Режим оценки\n    val_running_loss, val_running_corrects = 0.0, 0\n    with torch.no_grad():  # Без расчёта градиентов\n        for inputs, labels in tqdm(val_loader_model2, desc=f\"Модель №2 Эпоха {epoch+1}/{num_epochs_model2} [Валидация]\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model2(inputs)\n            loss = criterion2(outputs, labels)\n            val_running_loss += loss.item() * inputs.size(0)\n            preds = outputs.argmax(dim=1)\n            val_running_corrects += (preds == labels).sum().item()\n\n    # Средние значения лосса и точности на валидации\n    epoch_val_loss = val_running_loss / len(val_dataset_model2)\n    epoch_val_acc  = val_running_corrects / len(val_dataset_model2)\n    val_losses_model2.append(epoch_val_loss)\n    val_accs_model2.append(epoch_val_acc)\n\n    # Вывод результатов эпохи\n    print(f\"Эпоха {epoch+1}/{num_epochs_model2} — \"\n          f\"Обучение: лосс = {epoch_loss:.4f}, точность = {epoch_acc:.4f} | \"\n          f\"Валидация: лосс = {epoch_val_loss:.4f}, точность = {epoch_val_acc:.4f}\")\n\n    # --- Сохранение лучшей модели ---\n    if epoch_val_acc > best_val_acc2:\n        best_val_acc2 = epoch_val_acc\n        torch.save(model2.state_dict(), '/kaggle/working/model2_best.pth')\n        print(f\"  → Новая лучшая модель сохранена как model2_best.pth (валидационная точность: {best_val_acc2:.4f})\")\n\n# Визуализация лосса на обучении и валидации\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs_model2 + 1), train_losses_model2, label=\"Лосс на обучении\")\nplt.plot(range(1, num_epochs_model2 + 1), val_losses_model2, label=\"Лосс на валидации\")\nplt.xlabel(\"Эпоха\")\nplt.ylabel(\"Значение функции потерь\")\nplt.title(\"Модель №2: динамика функции потерь на обучении и валидации\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:39:07.039727Z","iopub.execute_input":"2025-04-29T19:39:07.039994Z","iopub.status.idle":"2025-04-29T19:42:28.030800Z","shell.execute_reply.started":"2025-04-29T19:39:07.039974Z","shell.execute_reply":"2025-04-29T19:42:28.029711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Построение матрицы ошибок для модели №2 ---\nmodel2.eval()  # Перевод модели в режим оценки\nall_preds2 = []   # Список предсказанных меток\nall_labels2 = []  # Список истинных меток\n\nwith torch.no_grad():  # Отключаем градиенты\n    for inputs, labels in tqdm(val_loader_model2, desc=\"Модель №2: Матрица ошибок\"):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model2(inputs)\n        _, preds = torch.max(outputs, 1)  # Определение предсказанных классов\n        all_preds2.extend(preds.cpu().numpy())\n        all_labels2.extend(labels.cpu().numpy())\n\n# Вычисление матрицы ошибок\ncm2 = confusion_matrix(all_labels2, all_preds2)\n\n# Визуализация матрицы ошибок\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm2, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=model2_target_names,\n            yticklabels=model2_target_names)\nplt.xlabel(\"Предсказанный класс\")\nplt.ylabel(\"Истинный класс\")\nplt.title(\"Модель №2: Матрица ошибок)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:42:28.031963Z","iopub.execute_input":"2025-04-29T19:42:28.032320Z","iopub.status.idle":"2025-04-29T19:42:31.823636Z","shell.execute_reply.started":"2025-04-29T19:42:28.032284Z","shell.execute_reply":"2025-04-29T19:42:31.822683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs, labels = next(iter(val_loader_model2))\ninputs = inputs.to(device)\noutputs = model2(inputs)\n_, preds = torch.max(outputs, 1)\nplt.figure(figsize=(15, 10))\nfor i in range(min(inputs.size(0), 16)):\n    ax = plt.subplot(4, 4, i+1)\n    imshow(inputs.cpu().data[i])\n    true_label = model2_target_names[labels[i]]\n    pred_label = model2_target_names[preds[i]]\n    ax.set_title(f\"Истинный: {true_label}\\nПредсказанный: {pred_label}\", fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T19:42:31.824904Z","iopub.execute_input":"2025-04-29T19:42:31.825259Z","iopub.status.idle":"2025-04-29T19:42:36.236995Z","shell.execute_reply.started":"2025-04-29T19:42:31.825228Z","shell.execute_reply":"2025-04-29T19:42:36.236024Z"}},"outputs":[],"execution_count":null}]}